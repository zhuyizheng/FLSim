{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "last_server_session_id": "",
  "last_kernel_id": "",
  "last_base_url": "",
  "last_msg_id": "",
  "outputWidgetContext": {},
  "colab": {
   "name": "cifar10_tutorial.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "ec4510e7-5bb1-45a2-ac60-57ca1906cf03",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "RcL6FFVmO_we"
   },
   "source": [
    "# FLSim Tutorial: Image classification with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "14df5562-53c7-42ee-bafa-a5bcc0e32826",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "9gIQhqPSO_wg"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will train a simple CNN image classifier on CIFAR-10 with federated learning using FLSim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "a4acb953-0669-4c3f-8ce9-4d798c87ca7a",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "qCwSd63HO_wg"
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "To get the most of this tutorial, you should be comfortable with training machine learning models with **PyTorch** and familiar with the concept of **federated learning (FL)**. If you are unfamiliar with either of them or could use a refresher, please take a look at the following resources before proceeding with the tutorial:\n",
    "\n",
    "- McMahan & Ramage (2017): [Federated Learning: Collaborative Machine Learning without Centralized Training Data](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html). A short blog post from Google AI introducing the main idea of FL in a beginner-friendly way.\n",
    "- McMahan et al. (2017): [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/pdf/1602.05629.pdf). This paper first proposes the approach of federated learning. The described algorithm is now known as federated averaging (or FedAvg for short).\n",
    "- PyTorch has [extensive tutorials](https://pytorch.org/tutorials/) on their website. In particular, take a look at their [image classification tutorial using CIFAR-10](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "Now that you're familiar with PyTorch and FL, let's move on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "eeb9679b-564f-41f4-ac5e-68af58d18d0b",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "90vb3wIbO_wg"
   },
   "source": [
    "### Objectives \n",
    "\n",
    "By the end of this tutorial, we will have learnt how to\n",
    "\n",
    "1. Build a data pipeline for federated learning with FLSim,\n",
    "2. Create an image classification model compatible with FL training,\n",
    "3. Create a metrics reporter to collect and report metrics,\n",
    "4. Set hyperparameters for FL training, and\n",
    "5. Launch an FL training flow using FLSim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "b82a213b-1dc9-4d0b-be5f-24f7341f25bd",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "SEk7EMBXO_wh"
   },
   "source": [
    "## Training an image classifier with FLSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av-rYy6_w7kT"
   },
   "source": [
    "### Prerequisites\n",
    "First, let us install flsim via pip with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cdMaaGUWjWbs",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:16.196350098Z",
     "start_time": "2023-10-25T07:51:16.111271056Z"
    }
   },
   "source": [
    "# !pip install --quiet flsim"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJ5ByjeMedhi"
   },
   "source": [
    "Some useful parameters for later - no need to change these."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jAWKDKuieYPO",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:16.251195740Z",
     "start_time": "2023-10-25T07:51:16.114858690Z"
    }
   },
   "source": [
    "USE_CUDA = True\n",
    "LOCAL_BATCH_SIZE = 32\n",
    "EXAMPLES_PER_USER = 500\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "# suppress large outputs\n",
    "VERBOSE = False"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "e78c1595-1416-4a95-8ace-e281555b052a",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "2DgQGgN0O_wi"
   },
   "source": [
    "### 0. About the dataset\n",
    "\n",
    "For this tutorial, we will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). The CIFAR-10 dataset consists of 60k 3x32x32 3-channel color images with 32x32 pixels from 10 classes, with 6k images per class. \n",
    "There are 50k training images (5k training images per class) and 10k test images (1k test images per class).\n",
    "The classes are ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, and ‘truck’.\n",
    "\n",
    "![img](https://pytorch.org/tutorials/_images/cifar10.png)\n",
    "\n",
    "We can get the CIFAR-10 dataset from `torchvision.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "originalKey": "f419c741-d171-4d8a-b731-4ae61916945c",
    "showInput": true,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "requestMsgId": "f419c741-d171-4d8a-b731-4ae61916945c",
    "executionStartTime": 1636504268213,
    "executionStopTime": 1636504272232,
    "id": "ii-IOAM6O_wi",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:17.782725227Z",
     "start_time": "2023-10-25T07:51:16.129425965Z"
    }
   },
   "source": [
    "from torchvision.datasets.cifar import CIFAR10"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "f476eb9e-a006-4cbc-81e2-585e771e6707",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "-NipUzoIO_wi"
   },
   "source": [
    "### 1. Data pipeline\n",
    "\n",
    "First, let's define how to build the data pipeline for federated learning:\n",
    "\n",
    "1. We create data transforms and training, eval, and test datasets. This step is identical to preparing data in non-federated learning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NE8WbhrhoYLk",
    "outputId": "bf447807-58c3-48f3-84c3-e833ec02629c",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:18.983082784Z",
     "start_time": "2023-10-25T07:51:17.809094235Z"
    }
   },
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 1. Create training, eval, and test datasets like in non-federated learning.\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.4914, 0.4822, 0.4465), \n",
    "            (0.2023, 0.1994, 0.2010)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "train_dataset = CIFAR10(\n",
    "    root=\"./cifar10\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = CIFAR10(\n",
    "    root=\"./cifar10\", train=False, download=True, transform=transform\n",
    ")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk0ckcDsoX8g"
   },
   "source": [
    "\n",
    "There are a few extra steps to enable training with federated learning. In particular, we need to\n",
    "\n",
    "2. Create a sharder, which defines a mapping from examples in the training data to clients. In other words, a sharder groups rows of data into client datasets and returns a list of list of examples. FLSim provides a number of sharding strategies such as random or column-based sharding. \n",
    "In this tutorial, we use sequential sharding, which assigns the first `examples_per_user` rows to user 0, the second `examples_per_user` rows to user 1, etc. \n",
    "\n",
    "3. Create a data loader, which will shard and batchify training, eval, and test data. For each dataset, the data loader first assigns rows to clients using the sharder and then splits each client's data into batches of size `batch_size`. We choose not to drop the last batch.\n",
    "\n",
    "4. Lastly, wrap the data loader with a data provider and return it. The data provider creates clients from the groupings in the data loader and adds metadata (e.g. number of examples/batches). Our data is now formatted such that the trainer will accept it.\n",
    "\n",
    "Note that the concept of a client or device only applies to the training data, the eval and test set data are identical to non-federated learning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljDjx6CRotTW",
    "outputId": "782521e0-dead-4a8a-ae90-fe61cc8c5cd9",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:34.923684365Z",
     "start_time": "2023-10-25T07:51:18.986820715Z"
    }
   },
   "source": [
    "from flsim.data.data_sharder import SequentialSharder\n",
    "from flsim.utils.example_utils import DataLoader, DataProvider\n",
    "\n",
    "# 2. Create a sharder, which maps samples in the training data to clients.\n",
    "sharder = SequentialSharder(examples_per_shard=EXAMPLES_PER_USER)\n",
    "\n",
    "# 3. Shard and batchify training, eval, and test data.\n",
    "fl_data_loader = DataLoader(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    sharder=sharder,\n",
    "    batch_size=LOCAL_BATCH_SIZE,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "# 4. Wrap the data loader with a data provider.\n",
    "data_provider = DataProvider(fl_data_loader)\n",
    "print(f\"\\nClients in total: {data_provider.num_train_users()}\")"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating FL User: 100user [00:11,  8.70user/s]\n",
      "Creating FL User: 20user [00:02,  9.28user/s]\n",
      "Creating FL User: 20user [00:02,  9.15user/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clients in total: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "06d24749-da10-4a1b-a48d-3810fda4ebf9",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "tpZ2H7jNO_wk"
   },
   "source": [
    "### 2. Create the model\n",
    "\n",
    "Now, let's see how we can create a model that is compatible with FL-training.\n",
    "\n",
    "1. First, we define a standard, non-FL image classification PyTorch `nn.Module.` In this tutorial we use a simple CNN with 4 convolutional layers, a group norm, and a linear layer. \n",
    "\n",
    "2. Create a `torch.device` and choose where the model will be allocated (CUDA or CPU).\n",
    "\n",
    "As with the data pipeline, these steps are identical to creating a model in non-federated learning. Note that in contrast to non-FL learning, we haven't moved the model to device yet."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "originalKey": "7d1549e0-5da1-4480-b581-0c46747a301d",
    "showInput": true,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "requestMsgId": "7d1549e0-5da1-4480-b581-0c46747a301d",
    "executionStartTime": 1636422569684,
    "executionStopTime": 1636422570122,
    "id": "ktgmrbTyO_wk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6ffdb2f8-3a55-4aff-b616-c904adbdd602",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:34.934747053Z",
     "start_time": "2023-10-25T07:51:34.923906066Z"
    }
   },
   "source": [
    "import torch\n",
    "from flsim.utils.example_utils import SimpleConvNet\n",
    "\n",
    "# 1. Define our model, a simple CNN.\n",
    "model = SimpleConvNet(in_channels=3, num_classes=10)\n",
    "\n",
    "# 2. Choose where the model will be allocated.\n",
    "cuda_enabled = torch.cuda.is_available() and USE_CUDA\n",
    "device = torch.device(f\"cuda:{0}\" if cuda_enabled else \"cpu\")\n",
    "\n",
    "model, device"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(SimpleConvNet(\n   (layers): ModuleList(\n     (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n     (1-3): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n   )\n   (gn_relu): Sequential(\n     (0): GroupNorm(32, 32, eps=1e-05, affine=True)\n     (1): ReLU()\n     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n   )\n   (dropout): Dropout(p=0, inplace=False)\n   (fc): Linear(in_features=288, out_features=10, bias=True)\n ),\n device(type='cpu'))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2tka3JhCyDx"
   },
   "source": [
    "As with the data pipeline, there are a few extra steps that we need to take to make sure that our model is compatible with FL. In particular, we need to\n",
    "\n",
    "3. Wrap the PyTorch module with the FLSim `FLModel`, an abstracted version of a FL-friendly model class that is accepted by the trainer and handles metric collection, as well as the forward pass for both training and evaluation. We can recover our `nn.Module` by calling `FLModel.fl_get_module()`\n",
    "\n",
    "4. Move the model to GPU and enable CUDA if desired. `FLModel.fl_cuda()` internally calls `model.to(device)` to move the model to GPU."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "originalKey": "fa53c62c-7732-4f31-b73a-3fd61a9ac6e0",
    "showInput": true,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "requestMsgId": "fa53c62c-7732-4f31-b73a-3fd61a9ac6e0",
    "executionStartTime": 1636422570217,
    "executionStopTime": 1636422570544,
    "id": "i1wVfw3OO_wl",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:34.937491217Z",
     "start_time": "2023-10-25T07:51:34.932585681Z"
    }
   },
   "source": [
    "from flsim.utils.example_utils import FLModel\n",
    "\n",
    "# 3. Wrap the model with FLModel.\n",
    "global_model = FLModel(model, device)\n",
    "assert(global_model.fl_get_module() == model)\n",
    "\n",
    "# 4. Move the model to GPU and enable CUDA if desired.\n",
    "if cuda_enabled:\n",
    "    global_model.fl_cuda()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJETpvZtDP0O"
   },
   "source": [
    "### 3. Metrics Reporting\n",
    "\n",
    "After having created our data pipeline and FL model, we will now create our metrics reporter. \n",
    "The metrics reporter allows us to collect, evaluate, and report relevant training, aggregation, and evaluation/test metrics as well as log them onto TensorBoard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S3dLLIn7ExUq",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:35.006272495Z",
     "start_time": "2023-10-25T07:51:34.942927647Z"
    }
   },
   "source": [
    "from flsim.interfaces.metrics_reporter import Channel\n",
    "from flsim.utils.example_utils import MetricsReporter\n",
    "\n",
    "# Create a metric reporter.\n",
    "metrics_reporter = MetricsReporter([Channel.TENSORBOARD, Channel.STDOUT])"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO3I_1GF6xzH"
   },
   "source": [
    "There are three functions that are of particular interest:\n",
    "\n",
    "1. `compute_scores` computes the metrics of interest for both training and aggregation (if desired) as well as evaluation/test.\n",
    "\n",
    "2. `create_eval_metrics` creates a dictionary that stores the value for each eval metric. \n",
    "\n",
    "3. `compare_metrics` compares the current eval metrics that are returned by `create_eval_metrics` to the best eval metrics so far.\n",
    "\n",
    "\n",
    "For this tutorial, our only metric of interest is top-1 accuracy. In general, as with the data loading and model, you should write your own metrics reporter depending on the task. For example, if you are running an NLP task you may want to have your metrics reporter track perplexity as well."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IfuzBfS76yGZ",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:35.006615362Z",
     "start_time": "2023-10-25T07:51:34.984814701Z"
    }
   },
   "source": [
    "import inspect\n",
    "\n",
    "if VERBOSE:\n",
    "    print(inspect.getsource(MetricsReporter.compute_scores))\n",
    "    print(inspect.getsource(MetricsReporter.create_eval_metrics))\n",
    "    print(inspect.getsource(MetricsReporter.compare_metrics))"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "983d685b-8e16-4efa-8a10-ec4ab73a69bc",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "ZmvB2-aNO_wl"
   },
   "source": [
    "### 4. Hyperparameters\n",
    "\n",
    "We can represent the hyperparameters for FL training in a JSON config for ease of representation and we convert the JSON config to OmegaConf before passing it to the FL trainer.\n",
    "\n",
    "In particular, we specify a FedAvg implementation with 10 users per round."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "originalKey": "3cdafa88-21b4-4080-ba20-2890431b32dd",
    "showInput": true,
    "customInput": null,
    "requestMsgId": "3cdafa88-21b4-4080-ba20-2890431b32dd",
    "executionStartTime": 1636422570651,
    "executionStopTime": 1636422571503,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "nMCgbRFEO_wl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac845a9e-df21-4c94-cf3c-667c111f9bbb",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:51:37.131838131Z",
     "start_time": "2023-10-25T07:51:34.984979621Z"
    }
   },
   "source": [
    "import flsim.configs\n",
    "from flsim.utils.config_utils import fl_config_from_json\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "json_config = {\n",
    "    \"trainer\": {\n",
    "        \"_base_\": \"base_sync_trainer\",\n",
    "        # there are different types of aggregator\n",
    "        # fed avg doesn't require lr, while others such as fed_avg_with_lr or fed_adam do\n",
    "        \"_base_\": \"base_sync_trainer\",\n",
    "        \"server\": {\n",
    "            \"_base_\": \"base_sync_server\",\n",
    "            \"server_optimizer\": {\n",
    "                \"_base_\": \"base_fed_avg_with_lr\",\n",
    "                \"lr\": 2.13,\n",
    "                \"momentum\": 0.9\n",
    "            },\n",
    "            # type of user selection sampling\n",
    "            \"active_user_selector\": {\"_base_\": \"base_uniformly_random_active_user_selector\"},\n",
    "        },\n",
    "        \"client\": {\n",
    "            # number of client's local epoch\n",
    "            \"epochs\": 1,\n",
    "            \"optimizer\": {\n",
    "                \"_base_\": \"base_optimizer_sgd\",\n",
    "                # client's local learning rate\n",
    "                \"lr\": 0.01,\n",
    "                # client's local momentum\n",
    "                \"momentum\": 0,\n",
    "            },\n",
    "        },\n",
    "        # number of users per round for aggregation\n",
    "        \"users_per_round\": 5,\n",
    "        # total number of global epochs\n",
    "        # total #rounds = ceil(total_users / users_per_round) * epochs\n",
    "        \"epochs\": 1,\n",
    "        # frequency of reporting train metrics\n",
    "        \"train_metrics_reported_per_epoch\": 100,\n",
    "        # frequency of evaluation per epoch\n",
    "        \"eval_epoch_frequency\": 1,\n",
    "        \"do_eval\": True,\n",
    "        # should we report train metrics after global aggregation\n",
    "        \"report_train_metrics_after_aggregation\": True,\n",
    "    }\n",
    "}\n",
    "cfg = fl_config_from_json(json_config)\n",
    "if VERBOSE: print(OmegaConf.to_yaml(cfg))"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu22/PycharmProjects/FLSim/flsim/utils/config_utils.py:198: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=None):\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "d3296d38-38da-44ea-ad8e-305de0c3e06d",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "GBvhMLL1O_wm"
   },
   "source": [
    "### 5. Training\n",
    "Recall that we already built the data provider and created a model compatible with FL training. \n",
    "We also initialized a metrics reporter and set our desired hyperparameters.\n",
    "\n",
    "Now, we only need to instantiate the trainer with the model and hyperparameter config we defined earlier to launch the FL training flow. We run FL training with the above JSON config and utilize `eval_score` to store the final evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "originalKey": "2eccb04f-229a-43f9-8310-0ced64132e2b",
    "showInput": true,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "requestMsgId": "2eccb04f-229a-43f9-8310-0ced64132e2b",
    "executionStartTime": 1636422644878,
    "executionStopTime": 1636422645173,
    "id": "kLWIpCxjO_wn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d344cfe0-60bd-475f-f57e-226621639d03",
    "ExecuteTime": {
     "end_time": "2023-10-25T07:53:59.473191624Z",
     "start_time": "2023-10-25T07:53:20.035520475Z"
    }
   },
   "source": [
    "from hydra.utils import instantiate\n",
    "\n",
    "# Instantiate the trainer.\n",
    "trainer = instantiate(cfg.trainer, model=global_model, cuda_enabled=cuda_enabled)   \n",
    "\n",
    "# Launch FL training.\n",
    "final_model, eval_score = trainer.train(\n",
    "    data_provider=data_provider,\n",
    "    metrics_reporter=metrics_reporter,\n",
    "    num_total_users=data_provider.num_train_users(),\n",
    "    distributed_world_size=1,\n",
    "    malicious_count=1,\n",
    "    attack_type='noise',  # 'scale', 'noise', 'flip'\n",
    "    attack_param={'scale_factor': -1.5,\n",
    "                  'noise_std': 0.1,\n",
    "                  'label_1': 5,\n",
    "                  'label_2': 9},\n",
    "    check_type='strict',  # 'no_check', 'strict', 'prob_zkp'\n",
    "    check_param={'pred': 'l2norm', # 'l2norm', 'sphere', 'cosine'\n",
    "                 'norm_bound': 0.2},\n",
    ")"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round:   0%|          | 0/20 [00:00<?, ?round/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** computing delta! ***\n",
      "delta norm before: 0.18197865784168243\n",
      "noise, delta norm after: 17.726133346557617\n",
      "check failed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.2043217271566391\n",
      "no attack\n",
      "delta norm after: 0.20000000298023224\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.2019915133714676\n",
      "no attack\n",
      "delta norm after: 0.20000000298023224\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.17443476617336273\n",
      "no attack\n",
      "delta norm after: 0.17443476617336273\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.17970216274261475\n",
      "no attack\n",
      "delta norm after: 0.17970216274261475\n",
      "check passed!\n",
      "Train finished Global Round: 1\n",
      "(epoch = 1, round = 1, global round = 1), Loss/Training: 1.6359465916951497\n",
      "(epoch = 1, round = 1, global round = 1), Accuracy/Training: 42.06161137440758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round:   5%|▌         | 1/20 [00:28<09:00, 28.44s/round]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch = 1, round = 1, global round = 1), Loss/Aggregation: 1.6238590151071548\n",
      "(epoch = 1, round = 1, global round = 1), Accuracy/Aggregation: 42.04\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.20613853633403778\n",
      "noise, delta norm after: 17.611501693725586\n",
      "check failed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.20751015841960907\n",
      "no attack\n",
      "delta norm after: 0.19999998807907104\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.18227913975715637\n",
      "no attack\n",
      "delta norm after: 0.18227913975715637\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.19321690499782562\n",
      "no attack\n",
      "delta norm after: 0.19321690499782562\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.17303138971328735\n",
      "no attack\n",
      "delta norm after: 0.17303138971328735\n",
      "check passed!\n",
      "Train finished Global Round: 2\n",
      "(epoch = 1, round = 2, global round = 2), Loss/Training: 1.6187740370631218\n",
      "(epoch = 1, round = 2, global round = 2), Accuracy/Training: 42.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round:  10%|█         | 2/20 [00:33<04:27, 14.89s/round]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch = 1, round = 2, global round = 2), Loss/Aggregation: 1.547975528240204\n",
      "(epoch = 1, round = 2, global round = 2), Accuracy/Aggregation: 45.52\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.1784418374300003\n",
      "noise, delta norm after: 17.747121810913086\n",
      "check failed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.1832793653011322\n",
      "no attack\n",
      "delta norm after: 0.1832793653011322\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.1650639921426773\n",
      "no attack\n",
      "delta norm after: 0.1650639921426773\n",
      "check passed!\n",
      "*** computing delta! ***\n",
      "delta norm before: 0.2472349852323532\n",
      "no attack\n",
      "delta norm after: 0.20000000298023224\n",
      "check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round:  10%|█         | 2/20 [00:39<05:52, 19.56s/round]\n",
      "Epoch:   0%|          | 0/1 [00:39<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m trainer \u001B[38;5;241m=\u001B[39m instantiate(cfg\u001B[38;5;241m.\u001B[39mtrainer, model\u001B[38;5;241m=\u001B[39mglobal_model, cuda_enabled\u001B[38;5;241m=\u001B[39mcuda_enabled)   \n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Launch FL training.\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m final_model, eval_score \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_provider\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_provider\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_total_users\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_provider\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_train_users\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistributed_world_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmalicious_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnoise\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 'scale', 'noise', 'flip'\u001B[39;49;00m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mscale_factor\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnoise_std\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel_1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel_2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 'no_check', 'strict', 'prob_zkp'\u001B[39;49;00m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpred\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43ml2norm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# 'l2norm', 'sphere', 'cosine'\u001B[39;49;00m\n\u001B[1;32m     20\u001B[0m \u001B[43m                 \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnorm_bound\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/trainers/sync_trainer.py:270\u001B[0m, in \u001B[0;36mSyncTrainer.train\u001B[0;34m(self, data_provider, metrics_reporter, num_total_users, distributed_world_size, rank, malicious_count, attack_type, attack_param, check_type, check_param)\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m#### Training phase ####\u001B[39;00m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;66;03m# Training on selected clients for this round; also calculate training\u001B[39;00m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;66;03m# metrics on `agg_metric_clients`\u001B[39;00m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# clients/round on worker \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrank\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(clients)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 270\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_one_round\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43magg_metric_clients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43magg_metric_clients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43musers_per_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musers_per_round\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmalicious_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmalicious_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreport_train_metrics\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39misEnabledFor(logging\u001B[38;5;241m.\u001B[39mDEBUG):\n\u001B[1;32m    286\u001B[0m     norm \u001B[38;5;241m=\u001B[39m FLModelParamUtils\u001B[38;5;241m.\u001B[39mdebug_model_norm(\n\u001B[1;32m    287\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_model()\u001B[38;5;241m.\u001B[39mfl_get_module()\n\u001B[1;32m    288\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/trainers/sync_trainer.py:481\u001B[0m, in \u001B[0;36mSyncTrainer._train_one_round\u001B[0;34m(self, timeline, clients, agg_metric_clients, users_per_round, malicious_count, attack_type, attack_param, check_type, check_param, metrics_reporter)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_train_one_round\u001B[39m(\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    460\u001B[0m     timeline: Timeline,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    469\u001B[0m     metrics_reporter: Optional[IFLMetricsReporter] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    471\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Trains the global model for one training round.\u001B[39;00m\n\u001B[1;32m    472\u001B[0m \n\u001B[1;32m    473\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m        metrics_reporter: Metric reporter to pass to other methods.\u001B[39;00m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 481\u001B[0m     server_return_metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_one_round_apply_updates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43magg_metric_clients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43magg_metric_clients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m        \u001B[49m\u001B[43musers_per_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musers_per_round\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmalicious_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmalicious_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattack_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    494\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_one_round_report_metrics(\n\u001B[1;32m    495\u001B[0m         timeline\u001B[38;5;241m=\u001B[39mtimeline,\n\u001B[1;32m    496\u001B[0m         clients\u001B[38;5;241m=\u001B[39mclients,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    500\u001B[0m         server_return_metrics\u001B[38;5;241m=\u001B[39mserver_return_metrics,\n\u001B[1;32m    501\u001B[0m     )\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_train_one_round(timeline)\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/trainers/sync_trainer.py:539\u001B[0m, in \u001B[0;36mSyncTrainer._train_one_round_apply_updates\u001B[0;34m(self, timeline, clients, agg_metric_clients, users_per_round, malicious_count, attack_type, attack_param, check_type, check_param, metrics_reporter)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m# Update client-side models from server-side model (in `server_state_message`)\u001B[39;00m\n\u001B[1;32m    538\u001B[0m t \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m--> 539\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_clients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver_state_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_state_message\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmalicious_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmalicious_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCollecting round\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms clients took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m s.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# After all clients finish their updates, update the global model\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/trainers/sync_trainer.py:447\u001B[0m, in \u001B[0;36mSyncTrainer._update_clients\u001B[0;34m(self, clients, server_state_message, malicious_count, attack_type, attack_param, check_type, check_param, metrics_reporter)\u001B[0m\n\u001B[1;32m    438\u001B[0m     client_delta, weight \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mgenerate_local_update(\n\u001B[1;32m    439\u001B[0m         message\u001B[38;5;241m=\u001B[39mserver_state_message,\n\u001B[1;32m    440\u001B[0m         attack_type\u001B[38;5;241m=\u001B[39mattack_type,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    444\u001B[0m         metrics_reporter\u001B[38;5;241m=\u001B[39mmetrics_reporter,\n\u001B[1;32m    445\u001B[0m     )\n\u001B[1;32m    446\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 447\u001B[0m     client_delta, weight \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_local_update\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_state_message\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mno_attack\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mreceive_update_from_client(Message(client_delta, weight), check_type, check_param)\n\u001B[1;32m    455\u001B[0m client_id \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/clients/base_client.py:156\u001B[0m, in \u001B[0;36mClient.generate_local_update\u001B[0;34m(self, message, attack_type, attack_param, check_type, check_param, metrics_reporter)\u001B[0m\n\u001B[1;32m    153\u001B[0m model \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_round_num \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39mglobal_round_num\n\u001B[0;32m--> 156\u001B[0m updated_model, weight, optimizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy_and_train_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattack_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_param\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# 4. Store updated model if being tracked\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore_last_updated_model:\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/clients/base_client.py:234\u001B[0m, in \u001B[0;36mClient.copy_and_train_model\u001B[0;34m(self, model, epochs, optimizer, optimizer_scheduler, attack_type, attack_param, metrics_reporter)\u001B[0m\n\u001B[1;32m    228\u001B[0m optim_scheduler \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    229\u001B[0m     default_scheduler \u001B[38;5;28;01mif\u001B[39;00m optimizer_scheduler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m optimizer_scheduler\n\u001B[1;32m    230\u001B[0m )\n\u001B[1;32m    232\u001B[0m \u001B[38;5;66;03m### yizheng 20231025 flip attack\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;66;03m# 3. Kick off training on client\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m updated_model, weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mupdated_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptim_scheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattack_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattack_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m updated_model, weight, optim\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/clients/base_client.py:381\u001B[0m, in \u001B[0;36mClient.train\u001B[0;34m(self, model, optimizer, optimizer_scheduler, attack_type, attack_param, metrics_reporter, epochs)\u001B[0m\n\u001B[1;32m    378\u001B[0m     batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m][mask1] \u001B[38;5;241m=\u001B[39m attack_param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel_2\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;66;03m# print(\"flipped labels, number of labels flipped:!\", torch.sum(mask1).item())\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# print(\"batch labels:\", batch['labels'])\u001B[39;00m\n\u001B[0;32m--> 381\u001B[0m sample_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_train\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetrics_reporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics_reporter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_scheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_scheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;66;03m# Optional post-processing after training on a batch\u001B[39;00m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_batch_train(epoch, model, sample_count, optimizer)\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/clients/base_client.py:475\u001B[0m, in \u001B[0;36mClient._batch_train\u001B[0;34m(self, model, optimizer, training_batch, epoch, metrics_reporter, optimizer_scheduler)\u001B[0m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Trains the client-side model for one batch.\u001B[39;00m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;124;03mCompatible with the new tasks in which the model is responsible for\u001B[39;00m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;124;03marranging its inputs, targets and context.\u001B[39;00m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;124;03m    Number of samples in the batch.\u001B[39;00m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    474\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 475\u001B[0m batch_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfl_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    476\u001B[0m loss \u001B[38;5;241m=\u001B[39m batch_metrics\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m    478\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/utils/example_utils.py:356\u001B[0m, in \u001B[0;36mFLModel.fl_forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    354\u001B[0m     features \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 356\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m     output, batch_label, stacked_label \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    360\u001B[0m         output\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[1;32m    361\u001B[0m         batch_label\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[1;32m    362\u001B[0m         stacked_label\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[1;32m    363\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/FLSim/flsim/utils/example_utils.py:330\u001B[0m, in \u001B[0;36mSimpleConvNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m--> 330\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgn_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    332\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_flat_features(x))\n\u001B[1;32m    333\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x))\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/activation.py:101\u001B[0m, in \u001B[0;36mReLU.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/functional.py:1471\u001B[0m, in \u001B[0;36mrelu\u001B[0;34m(input, inplace)\u001B[0m\n\u001B[1;32m   1469\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m   1470\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1471\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1472\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "6af80324-793c-4678-9143-80c89f6b299b",
    "showInput": false,
    "customInput": null,
    "id": "EKc8SBAtO_wo"
   },
   "source": [
    "After training finishes, we evaluate the model and report the accuracy on the test set before finishing this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "originalKey": "6ebd30d1-c3eb-437b-8719-1056167baaf9",
    "showInput": true,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "requestMsgId": "6ebd30d1-c3eb-437b-8719-1056167baaf9",
    "executionStopTime": 1636423399091,
    "executionStartTime": 1636423389997,
    "id": "PKUbnLbZO_wo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1fc1003b-845b-484d-dc97-56df628f8553",
    "ExecuteTime": {
     "end_time": "2023-10-24T01:58:37.365754519Z",
     "start_time": "2023-10-24T01:58:33.803773029Z"
    }
   },
   "source": [
    "# We can now test our trained model.\n",
    "trainer.test(\n",
    "    data_provider=data_provider,\n",
    "    metrics_reporter=MetricsReporter([Channel.STDOUT]),\n",
    ")"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running (epoch = 1, round = 1, global round = 1) for Test\n",
      "(epoch = 1, round = 1, global round = 1), Loss/Test: 1.4767778711393476\n",
      "(epoch = 1, round = 1, global round = 1), Accuracy/Test: 46.96\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Accuracy': 46.96}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "d8235e4e-b860-4554-aa5d-fa4a8c312467",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "oM2ozTxJO_wo"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we first showed how to get the data. We then built a data provider by sharding the data to simulate multiple client devices, each with their own data, and splitting each client's data into batches. \n",
    "We defined a simple CNN as our model, wrapped it with a model compatible with FL training, and moved it to GPU. \n",
    "Lastly, we set the hyperparameters for FL training, launched the training flow, and evaluated our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "462e5328-7112-48b5-abcc-b2599aeb9c94",
    "showInput": false,
    "customInput": null,
    "code_folding": [],
    "hidden_ranges": [],
    "id": "uH-Gqo8UO_wo"
   },
   "source": [
    "### Additional resources\n",
    "\n",
    "- For a more in-depth understanding of this tutorial, check out [example_utils.py](https://github.com/facebookresearch/FLSim/blob/main/flsim/utils/example_utils.py) where we define the data loader, data provider, simple CNN, `FLModel`, and metrics reporter that we use in this tutorial.\n",
    "\n",
    "- [FLSim tutorials](https://github.com/facebookresearch/FLSim/tree/main/tutorials) - check out our other tutorial on sentiment classification.\n",
    "\n",
    "- Kairouz et al. (2021): [Advances and Open Problems in Federated Learning](https://arxiv.org/pdf/1912.04977.pdf). As the title suggests, an in-depth overview of advances and open problems in FL.\n",
    "\n",
    "- If you're interested in federated learning with differential privacy, take a look at [Opacus](https://opacus.ai/), a library that enables training PyTorch models with differential privacy. \n",
    "You can find a blog post introducing Opacus [here](https://ai.facebook.com/blog/introducing-opacus-a-high-speed-library-for-training-pytorch-models-with-differential-privacy/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
