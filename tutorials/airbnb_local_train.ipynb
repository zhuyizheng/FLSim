{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from flsim.utils.example_utils import SimpleConvNet\n",
    "from medmnist import OrganAMNIST, OrganSMNIST\n",
    "from torch.utils.data import Dataset\n",
    "from flsim.data.data_sharder import SequentialSharder, PowerLawSharder\n",
    "from flsim.utils.example_utils import DataLoader, DataProvider\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import argparse\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:32:12.193718112Z",
     "start_time": "2023-11-17T07:32:10.219144150Z"
    }
   },
   "id": "7bb78c1204502e18"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_file = 'airbnb/AB_NYC_2019.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df[df['price'] != 0]\n",
    "df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "\n",
    "# Calculate the number of days from December 31, 2019\n",
    "reference_date = pd.to_datetime('2019-12-31')\n",
    "df['last_review'] = (df['last_review'] - reference_date).dt.days\n",
    "\n",
    "X = df.drop(['price', 'name', 'host_name', 'id', 'host_id'], axis=1)\n",
    "y = df['price']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:32:13.038155028Z",
     "start_time": "2023-11-17T07:32:12.896851674Z"
    }
   },
   "id": "2e472345fdc813eb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      neighbourhood_group    neighbourhood  latitude  longitude  \\\n0                Brooklyn       Kensington  40.64749  -73.97237   \n1               Manhattan          Midtown  40.75362  -73.98377   \n3                Brooklyn     Clinton Hill  40.68514  -73.95976   \n4               Manhattan      East Harlem  40.79851  -73.94399   \n5               Manhattan      Murray Hill  40.74767  -73.97500   \n...                   ...              ...       ...        ...   \n48782           Manhattan  Upper East Side  40.78099  -73.95366   \n48790              Queens         Flushing  40.75104  -73.81459   \n48799       Staten Island      Great Kills  40.54179  -74.14275   \n48805               Bronx       Mott Haven  40.80787  -73.92400   \n48852            Brooklyn         Bushwick  40.69805  -73.92801   \n\n             room_type  minimum_nights  number_of_reviews  last_review  \\\n0         Private room               1                  9         -438   \n1      Entire home/apt               1                 45         -224   \n3      Entire home/apt               1                270         -179   \n4      Entire home/apt              10                  9         -407   \n5      Entire home/apt               3                 74         -192   \n...                ...             ...                ...          ...   \n48782     Private room               1                  1         -177   \n48790     Private room               1                  1         -177   \n48799     Private room               1                  1         -177   \n48805  Entire home/apt               1                  2         -177   \n48852     Private room               1                  1         -176   \n\n       reviews_per_month  calculated_host_listings_count  availability_365  \n0                   0.21                               6               365  \n1                   0.38                               2               355  \n3                   4.64                               1               194  \n4                   0.10                               1                 0  \n5                   0.59                               1               129  \n...                  ...                             ...               ...  \n48782               1.00                               1               147  \n48790               1.00                               6               339  \n48799               1.00                               1                87  \n48805               2.00                               1                40  \n48852               1.00                               1                 1  \n\n[38811 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neighbourhood_group</th>\n      <th>neighbourhood</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>room_type</th>\n      <th>minimum_nights</th>\n      <th>number_of_reviews</th>\n      <th>last_review</th>\n      <th>reviews_per_month</th>\n      <th>calculated_host_listings_count</th>\n      <th>availability_365</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Brooklyn</td>\n      <td>Kensington</td>\n      <td>40.64749</td>\n      <td>-73.97237</td>\n      <td>Private room</td>\n      <td>1</td>\n      <td>9</td>\n      <td>-438</td>\n      <td>0.21</td>\n      <td>6</td>\n      <td>365</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Manhattan</td>\n      <td>Midtown</td>\n      <td>40.75362</td>\n      <td>-73.98377</td>\n      <td>Entire home/apt</td>\n      <td>1</td>\n      <td>45</td>\n      <td>-224</td>\n      <td>0.38</td>\n      <td>2</td>\n      <td>355</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Brooklyn</td>\n      <td>Clinton Hill</td>\n      <td>40.68514</td>\n      <td>-73.95976</td>\n      <td>Entire home/apt</td>\n      <td>1</td>\n      <td>270</td>\n      <td>-179</td>\n      <td>4.64</td>\n      <td>1</td>\n      <td>194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Manhattan</td>\n      <td>East Harlem</td>\n      <td>40.79851</td>\n      <td>-73.94399</td>\n      <td>Entire home/apt</td>\n      <td>10</td>\n      <td>9</td>\n      <td>-407</td>\n      <td>0.10</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Manhattan</td>\n      <td>Murray Hill</td>\n      <td>40.74767</td>\n      <td>-73.97500</td>\n      <td>Entire home/apt</td>\n      <td>3</td>\n      <td>74</td>\n      <td>-192</td>\n      <td>0.59</td>\n      <td>1</td>\n      <td>129</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48782</th>\n      <td>Manhattan</td>\n      <td>Upper East Side</td>\n      <td>40.78099</td>\n      <td>-73.95366</td>\n      <td>Private room</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-177</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>48790</th>\n      <td>Queens</td>\n      <td>Flushing</td>\n      <td>40.75104</td>\n      <td>-73.81459</td>\n      <td>Private room</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-177</td>\n      <td>1.00</td>\n      <td>6</td>\n      <td>339</td>\n    </tr>\n    <tr>\n      <th>48799</th>\n      <td>Staten Island</td>\n      <td>Great Kills</td>\n      <td>40.54179</td>\n      <td>-74.14275</td>\n      <td>Private room</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-177</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>48805</th>\n      <td>Bronx</td>\n      <td>Mott Haven</td>\n      <td>40.80787</td>\n      <td>-73.92400</td>\n      <td>Entire home/apt</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-177</td>\n      <td>2.00</td>\n      <td>1</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>48852</th>\n      <td>Brooklyn</td>\n      <td>Bushwick</td>\n      <td>40.69805</td>\n      <td>-73.92801</td>\n      <td>Private room</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-176</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>38811 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:32:19.167341083Z",
     "start_time": "2023-11-17T07:32:19.161018206Z"
    }
   },
   "id": "e6997e1628b8885f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group 5\n",
      "neighbourhood 218\n",
      "room_type 3\n",
      "categorical columns: ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
      "categorical dims: {'neighbourhood_group': 5, 'neighbourhood': 218, 'room_type': 3}\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in X.columns[X.dtypes == object]:\n",
    "    print(col, X[col].nunique())\n",
    "    l_enc = LabelEncoder()\n",
    "    X[col] = X[col].fillna(\"VV_likely\")\n",
    "    X[col] = l_enc.fit_transform(X[col].values)\n",
    "    categorical_columns.append(col)\n",
    "    categorical_dims[col] = len(l_enc.classes_)\n",
    "\n",
    "\n",
    "print(\"categorical columns:\", categorical_columns)\n",
    "print(\"categorical dims:\", categorical_dims)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:32:25.011387942Z",
     "start_time": "2023-11-17T07:32:24.942186397Z"
    }
   },
   "id": "955d4f2aefd9f237"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       neighbourhood_group  neighbourhood  latitude  longitude  room_type  \\\n0                        1            107  40.64749  -73.97237          1   \n1                        2            126  40.75362  -73.98377          0   \n3                        1             41  40.68514  -73.95976          0   \n4                        2             61  40.79851  -73.94399          0   \n5                        2            136  40.74767  -73.97500          0   \n...                    ...            ...       ...        ...        ...   \n48782                    2            199  40.78099  -73.95366          1   \n48790                    3             77  40.75104  -73.81459          1   \n48799                    4             89  40.54179  -74.14275          1   \n48805                    0            133  40.80787  -73.92400          0   \n48852                    1             28  40.69805  -73.92801          1   \n\n       minimum_nights  number_of_reviews  last_review  reviews_per_month  \\\n0                   1                  9         -438               0.21   \n1                   1                 45         -224               0.38   \n3                   1                270         -179               4.64   \n4                  10                  9         -407               0.10   \n5                   3                 74         -192               0.59   \n...               ...                ...          ...                ...   \n48782               1                  1         -177               1.00   \n48790               1                  1         -177               1.00   \n48799               1                  1         -177               1.00   \n48805               1                  2         -177               2.00   \n48852               1                  1         -176               1.00   \n\n       calculated_host_listings_count  availability_365  \n0                                   6               365  \n1                                   2               355  \n3                                   1               194  \n4                                   1                 0  \n5                                   1               129  \n...                               ...               ...  \n48782                               1               147  \n48790                               6               339  \n48799                               1                87  \n48805                               1                40  \n48852                               1                 1  \n\n[38811 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neighbourhood_group</th>\n      <th>neighbourhood</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>room_type</th>\n      <th>minimum_nights</th>\n      <th>number_of_reviews</th>\n      <th>last_review</th>\n      <th>reviews_per_month</th>\n      <th>calculated_host_listings_count</th>\n      <th>availability_365</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>107</td>\n      <td>40.64749</td>\n      <td>-73.97237</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>-438</td>\n      <td>0.21</td>\n      <td>6</td>\n      <td>365</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>126</td>\n      <td>40.75362</td>\n      <td>-73.98377</td>\n      <td>0</td>\n      <td>1</td>\n      <td>45</td>\n      <td>-224</td>\n      <td>0.38</td>\n      <td>2</td>\n      <td>355</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>41</td>\n      <td>40.68514</td>\n      <td>-73.95976</td>\n      <td>0</td>\n      <td>1</td>\n      <td>270</td>\n      <td>-179</td>\n      <td>4.64</td>\n      <td>1</td>\n      <td>194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>61</td>\n      <td>40.79851</td>\n      <td>-73.94399</td>\n      <td>0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>-407</td>\n      <td>0.10</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>136</td>\n      <td>40.74767</td>\n      <td>-73.97500</td>\n      <td>0</td>\n      <td>3</td>\n      <td>74</td>\n      <td>-192</td>\n      <td>0.59</td>\n      <td>1</td>\n      <td>129</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48782</th>\n      <td>2</td>\n      <td>199</td>\n      <td>40.78099</td>\n      <td>-73.95366</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-177</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>48790</th>\n      <td>3</td>\n      <td>77</td>\n      <td>40.75104</td>\n      <td>-73.81459</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-177</td>\n      <td>1.00</td>\n      <td>6</td>\n      <td>339</td>\n    </tr>\n    <tr>\n      <th>48799</th>\n      <td>4</td>\n      <td>89</td>\n      <td>40.54179</td>\n      <td>-74.14275</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-177</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>48805</th>\n      <td>0</td>\n      <td>133</td>\n      <td>40.80787</td>\n      <td>-73.92400</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-177</td>\n      <td>2.00</td>\n      <td>1</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>48852</th>\n      <td>1</td>\n      <td>28</td>\n      <td>40.69805</td>\n      <td>-73.92801</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-176</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>38811 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:32:26.433841806Z",
     "start_time": "2023-11-17T07:32:26.415637565Z"
    }
   },
   "id": "aaa482ba191e653"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:39:00.970682744Z",
     "start_time": "2023-11-17T07:39:00.926972448Z"
    }
   },
   "id": "4324897019795d63"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 75],\n       [130],\n       [100],\n       ...,\n       [100],\n       [219],\n       [169]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:39:06.649075994Z",
     "start_time": "2023-11-17T07:39:06.636658801Z"
    }
   },
   "id": "8c2e0198564d048b"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu22/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "features = [ col for col in X.columns] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "neighbourhood_embed_dim = 5  # number of embedding size of neighbourhood\n",
    "cat_emb_dim = [1, neighbourhood_embed_dim, 1]\n",
    "\n",
    "scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                  \"gamma\":0.9}\n",
    "scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
    "\n",
    "clf = TabNetRegressor(cat_dims=cat_dims, cat_emb_dim=cat_emb_dim, cat_idxs=cat_idxs, n_steps=10\n",
    "                      # , scheduler_params = scheduler_params, scheduler_fn=scheduler_fn\n",
    "                      )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:50:35.159541554Z",
     "start_time": "2023-11-17T07:50:35.145011451Z"
    }
   },
   "id": "f418ca69c994854e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "TabNetRegressor(n_d=8, n_a=8, n_steps=10, gamma=1.3, cat_idxs=[0, 1, 4], cat_dims=[5, 218, 3], cat_emb_dim=[1, 5, 1], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='auto', n_shared_decoder=1, n_indep_decoder=1, grouped_features=[])",
      "text/html": "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabNetRegressor(n_d=8, n_a=8, n_steps=10, gamma=1.3, cat_idxs=[0, 1, 4], cat_dims=[5, 218, 3], cat_emb_dim=[1, 5, 1], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;, optimizer_params={&#x27;lr&#x27;: 0.02}, scheduler_fn=None, scheduler_params={}, mask_type=&#x27;sparsemax&#x27;, input_dim=None, output_dim=None, device_name=&#x27;auto&#x27;, n_shared_decoder=1, n_indep_decoder=1, grouped_features=[])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TabNetRegressor</label><div class=\"sk-toggleable__content\"><pre>TabNetRegressor(n_d=8, n_a=8, n_steps=10, gamma=1.3, cat_idxs=[0, 1, 4], cat_dims=[5, 218, 3], cat_emb_dim=[1, 5, 1], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;, optimizer_params={&#x27;lr&#x27;: 0.02}, scheduler_fn=None, scheduler_params={}, mask_type=&#x27;sparsemax&#x27;, input_dim=None, output_dim=None, device_name=&#x27;auto&#x27;, n_shared_decoder=1, n_indep_decoder=1, grouped_features=[])</pre></div></div></div></div></div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:50:37.729650135Z",
     "start_time": "2023-11-17T07:50:37.721531890Z"
    }
   },
   "id": "bb99f2668681e48d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "max_epochs = 100 # default: 300"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:35:38.602903374Z",
     "start_time": "2023-11-17T07:35:38.554081717Z"
    }
   },
   "id": "1c9306ac44438a79"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "aug = RegressionSMOTE(p=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:50:41.471160792Z",
     "start_time": "2023-11-17T07:50:41.424848869Z"
    }
   },
   "id": "cda77031336e799c"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 50500.81585| train_rmsle: 1.31451 | train_mae: 240.85521| train_rmse: 319.80053| train_mse: 102272.37847| valid_rmsle: 1.31185 | valid_mae: 238.13752| valid_rmse: 305.12703| valid_mse: 93102.50473|  0:00:06s\n",
      "epoch 1  | loss: 37596.93317| train_rmsle: 1.14874 | train_mae: 185.30075| train_rmse: 259.37429| train_mse: 67275.0228| valid_rmsle: 1.14592 | valid_mae: 182.0934| valid_rmse: 238.20641| valid_mse: 56742.29518|  0:00:13s\n",
      "epoch 2  | loss: 36732.99072| train_rmsle: 1.52225 | train_mae: 362.37638| train_rmse: 460.24067| train_mse: 211821.47633| valid_rmsle: 1.52927 | valid_mae: 363.04306| valid_rmse: 453.19573| valid_mse: 205386.37415|  0:00:19s\n",
      "epoch 3  | loss: 36434.91944| train_rmsle: 0.89265 | train_mae: 128.94713| train_rmse: 227.84339| train_mse: 51912.61095| valid_rmsle: 0.88947 | valid_mae: 126.89145| valid_rmse: 204.32984| valid_mse: 41750.68223|  0:00:26s\n",
      "epoch 4  | loss: 35948.42302| train_rmsle: 0.6877  | train_mae: 89.82832| train_rmse: 201.23193| train_mse: 40494.29083| valid_rmsle: 0.67958 | valid_mae: 87.37446| valid_rmse: 173.94427| valid_mse: 30256.60926|  0:00:33s\n",
      "epoch 5  | loss: 36176.49318| train_rmsle: 0.51361 | train_mae: 61.12103| train_rmse: 191.94947| train_mse: 36844.59872| valid_rmsle: 0.5073  | valid_mae: 58.41129| valid_rmse: 162.93953| valid_mse: 26549.28891|  0:00:39s\n",
      "epoch 6  | loss: 34081.05981| train_rmsle: 0.54772 | train_mae: 66.35241| train_rmse: 191.17564| train_mse: 36548.12642| valid_rmsle: 0.54326 | valid_mae: 63.73504| valid_rmse: 163.00746| valid_mse: 26571.43266|  0:00:46s\n",
      "epoch 7  | loss: 36325.53523| train_rmsle: 0.52232 | train_mae: 62.57772| train_rmse: 192.3434| train_mse: 36995.98244| valid_rmsle: 0.51671 | valid_mae: 60.08209| valid_rmse: 163.07807| valid_mse: 26594.45729|  0:00:53s\n",
      "epoch 8  | loss: 36217.21142| train_rmsle: 0.51576 | train_mae: 61.39248| train_rmse: 191.15352| train_mse: 36539.66988| valid_rmsle: 0.50706 | valid_mae: 58.76813| valid_rmse: 162.18693| valid_mse: 26304.60167|  0:01:00s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvalid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrmsle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmae\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrmse\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmse\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvirtual_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdrop_last\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43maugmentations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m#aug\u001B[39;49;00m\n\u001B[1;32m     12\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:258\u001B[0m, in \u001B[0;36mTabModel.fit\u001B[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_epochs):\n\u001B[1;32m    254\u001B[0m \n\u001B[1;32m    255\u001B[0m     \u001B[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001B[39;00m\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_container\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch_idx)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Apply predict epoch to all eval sets\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m eval_name, valid_dataloader \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(eval_names, valid_dataloaders):\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:489\u001B[0m, in \u001B[0;36mTabModel._train_epoch\u001B[0;34m(self, train_loader)\u001B[0m\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (X, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[1;32m    487\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_container\u001B[38;5;241m.\u001B[39mon_batch_begin(batch_idx)\n\u001B[0;32m--> 489\u001B[0m     batch_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    491\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_container\u001B[38;5;241m.\u001B[39mon_batch_end(batch_idx, batch_logs)\n\u001B[1;32m    493\u001B[0m epoch_logs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer\u001B[38;5;241m.\u001B[39mparam_groups[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:527\u001B[0m, in \u001B[0;36mTabModel._train_batch\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetwork\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[1;32m    525\u001B[0m     param\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 527\u001B[0m output, M_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    529\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(output, y)\n\u001B[1;32m    530\u001B[0m \u001B[38;5;66;03m# Add the overall sparsity loss\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:616\u001B[0m, in \u001B[0;36mTabNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    614\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    615\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedder(x)\n\u001B[0;32m--> 616\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtabnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:492\u001B[0m, in \u001B[0;36mTabNetNoEmbeddings.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    491\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 492\u001B[0m     steps_output, M_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    493\u001B[0m     res \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mstack(steps_output, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    495\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_multi_task:\n\u001B[1;32m    496\u001B[0m         \u001B[38;5;66;03m# Result will be in list format\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:181\u001B[0m, in \u001B[0;36mTabNetEncoder.forward\u001B[0;34m(self, x, prior)\u001B[0m\n\u001B[1;32m    179\u001B[0m M_feature_level \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(M, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup_attention_matrix)\n\u001B[1;32m    180\u001B[0m masked_x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmul(M_feature_level, x)\n\u001B[0;32m--> 181\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeat_transformers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmasked_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m d \u001B[38;5;241m=\u001B[39m ReLU()(out[:, : \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_d])\n\u001B[1;32m    183\u001B[0m steps_output\u001B[38;5;241m.\u001B[39mappend(d)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:737\u001B[0m, in \u001B[0;36mFeatTransformer.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 737\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshared\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    738\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecifics(x)\n\u001B[1;32m    739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:774\u001B[0m, in \u001B[0;36mGLU_Block.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    772\u001B[0m scale \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msqrt(torch\u001B[38;5;241m.\u001B[39mFloatTensor([\u001B[38;5;241m0.5\u001B[39m])\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice))\n\u001B[1;32m    773\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst:  \u001B[38;5;66;03m# the first layer of the block has no scale multiplication\u001B[39;00m\n\u001B[0;32m--> 774\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mglu_layers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    775\u001B[0m     layers_left \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_glu)\n\u001B[1;32m    776\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:804\u001B[0m, in \u001B[0;36mGLU_Layer.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    803\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(x)\n\u001B[0;32m--> 804\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    805\u001B[0m     out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmul(x[:, : \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_dim], torch\u001B[38;5;241m.\u001B[39msigmoid(x[:, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_dim :]))\n\u001B[1;32m    806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:36\u001B[0m, in \u001B[0;36mGBN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     35\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mceil(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvirtual_batch_size)), \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 36\u001B[0m     res \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn(x_) \u001B[38;5;28;01mfor\u001B[39;00m x_ \u001B[38;5;129;01min\u001B[39;00m chunks]\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(res, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:36\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     35\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mceil(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvirtual_batch_size)), \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 36\u001B[0m     res \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x_ \u001B[38;5;129;01min\u001B[39;00m chunks]\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(res, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    164\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    166\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39-flsim/lib/python3.9/site-packages/torch/nn/functional.py:2478\u001B[0m, in \u001B[0;36mbatch_norm\u001B[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[1;32m   2475\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[1;32m   2476\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m-> 2478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2479\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[1;32m   2480\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=50,\n",
    "    batch_size=512, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # augmentations=aug, #aug\n",
    ") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:51:49.910557716Z",
     "start_time": "2023-11-17T07:50:47.421164942Z"
    }
   },
   "id": "87d69d6efad4871"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "test_score = mean_squared_error(y_pred=preds, y_true=y_true)\n",
    "\n",
    "print(f\"BEST VALID SCORE : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE : {test_score}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca6946d07f389601"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
